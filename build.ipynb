{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Memes Library Builder\n","\n","This library contains tens of thousands of memes organized in hundreds of folders by topic. This notebook builds the master json file which contains a list of all the topics, all the memes in each topic, and a list of any metadata associated with each meme.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Import Libraries\n","\n","import os\n","import json\n","from glob import glob\n","from pathlib import Path\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Define Constants\n","\n","MEMES_ROOT = Path('memes')\n"]},{"cell_type":"markdown","metadata":{},"source":["# Create missing first-seen files\n","\n","Iterate recursively through all the subdirectories of the ./memes folder and for any file with one of the following extensions, check if it already has a file with the same name in the same directory but appended with first-seen.txt. So for example meme.jpg meansthere should also be a file called meme.jpg.first-seen.txt  \n","\n","If not, create a new file containing the file modification time as a python datetime. This file should have the same name but appended with first-seen.txt. So for example meme.jpg means we need to create a file called meme.jpg.first-seen.txt containing the python datetime of the modification time of the meme.jpg file.  \n","\n","- .gif\n","- .jfif\n","- .jpeg\n","- .jpg\n","- .mp4\n","- .png\n","- .svg\n","- .webp\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from pathlib import Path\n","from datetime import datetime, timezone, timedelta\n","\n","\n","TRACKED_EXTS = {\n","    \".gif\", \".jfif\", \".jpeg\", \".jpg\",\n","    \".mp4\", \".png\", \".svg\", \".webp\",\n","}\n","\n","IMAGE_EXTS   = {\".jpeg\", \".jpg\", \".png\"}\n","\n","def ensure_first_seen_files(root: Path, exts: set[str]) -> dict[str, int]:\n","    created = 0\n","    skipped = 0\n","\n","    for file in root.rglob(\"*\"):\n","        if file.suffix.lower() not in exts or not file.is_file():\n","            continue\n","\n","        meta_path = file.with_name(file.name + \".first-seen.txt\")\n","\n","        if meta_path.exists():\n","            skipped += 1\n","            continue\n","\n","        # ‚ñ∂ grab mtime and convert to UTC datetime\n","        mod_time = datetime.fromtimestamp(file.stat().st_mtime,\n","                                          tz=timezone.utc)\n","        # ‚ñ∂ write ISO-8601 string\n","        meta_path.write_text(mod_time.isoformat())\n","\n","        created += 1\n","\n","    return {\"created\": created, \"skipped\": skipped}\n","\n","summary = ensure_first_seen_files(MEMES_ROOT, TRACKED_EXTS)\n","print(f\"First-seen files created: {summary['created']}\")\n","print(f\"Already present / skipped : {summary['skipped']}\")"]},{"cell_type":"markdown","metadata":{"tags":[]},"source":["# Build the master memes.json file\n","\n","The memes are organized like so;\n","/memes/Topic 1\n","/memes/Topic 2\n","\n","Memes can be images or videos. Assume all the common file extensions will be present. For each meme, a number of metadata files may be present. These should be included if present.\n","\n","For example;\n","memefilename.jpg\n","memefilename.jpg.txt <- Canonical tesseract-OCR of the meme. Might be nonsense. Probably we won't need this but it's there, so lets include it in the json file.\n","memefilename.jpg.llama-3.2-vision.txt <- High quality transformer analysis of the image, containing detailed explanation of the visual elements of the image, including any text, but probably lacking an awareness of any social context or any relationship to current events.\n","\n","Example output:\n","\n","'Topic 1' => {\n","    1 => {\n","        'file' => 'memes/topic/filename.jpg',\n","        'filemtime' => 'date the file was last modified',\n","        'metadata' => {\n","            'tesseract-ocr' => 'memes/topic/filename.jpg.txt',\n","            'llama-3.2-vision' => 'memes/topic/filename.jpg.llama-3.2-vision.txt'\n","        }\n","    }\n","}\n","\n","The list of memes in each topic must be ordered by filemtime descending, such that the most recently added item is number 1. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["! pip install html5lib\n","\n","# Helper functions\n","import html\n","\n","from html5lib.serializer import escape as _h5_escape\n","\n","# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","#  HTML-5 escaping  +  extra Liquid-safety for curly braces\n","# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","def escape_entities(text: str) -> str:\n","    \"\"\"\n","    ‚Ä¢ Encode &, <, >, quotes (html5lib default).\n","    ‚Ä¢ ALSO encode { and } so accidental `{{` / `{%` from OCR\n","      can‚Äôt be parsed by Liquid.\n","    ‚Ä¢ Collapse newlines to single spaces.\n","    \"\"\"\n","    return (\n","        _h5_escape(\n","            text,\n","            entities={\n","                '\"': \"&quot;\",      # keep attribute-safe quotes\n","                \"'\": \"&#x27;\",      # HTML5‚Äêpreferred apostrophe\n","                \"{\": \"&#123;\",      # <-- Liquid-safety\n","                \"}\": \"&#125;\",      # <-- Liquid-safety\n","            },\n","        )\n","        .replace(\"\\n\", \" \")\n","    )\n","\n","def format_duration(seconds):\n","    seconds = int(seconds)\n","    mins, sec = divmod(seconds, 60)\n","    hrs, mins = divmod(mins, 60)\n","    days, hrs = divmod(hrs, 24)\n","    parts = []\n","    if days: parts.append(f'{days}d')\n","    if hrs: parts.append(f'{hrs}h')\n","    if mins: parts.append(f'{mins}m')\n","    if sec or not parts: parts.append(f'{sec}s')\n","    return ' '.join(parts)\n","\n","def read_text_multi(path: Path, encodings=('utf-8', 'utf-8-sig', 'cp1252', 'latin-1')):\n","    \"Try multiple encodings and fall back to replacement.\"\n","    for enc in encodings:\n","        try:\n","            return path.read_text(encoding=enc)\n","        except UnicodeDecodeError:\n","            pass\n","    return path.read_text(encoding=encodings[0], errors='replace')\n","\n","def get_file_timestamp(file: Path) -> datetime:\n","    \n","    file = Path(file)\n","    \n","    meta_path = file.with_name(file.name + \".first-seen.txt\")\n","\n","    if meta_path.exists():\n","        # Read the timestamp from first-seen.txt\n","        mod_time_str = read_text_multi(meta_path).strip()\n","        return mod_time_str\n","    else:\n","        # Fallback to current modification time\n","        return datetime.fromtimestamp(file.stat().st_mtime, tz=timezone.utc).isoformat()\n","    \n","def get_topics():\n","    \"\"\"Return list of topic folders in the memes directory\"\"\"\n","    return [p.name for p in MEMES_ROOT.iterdir() if p.is_dir()]\n","\n","def process_topic(topic: str) -> dict[int, dict]:\n","    topic_path = Path(MEMES_ROOT) / topic\n","    memes: list[dict] = []\n","\n","    for meme_file in topic_path.iterdir():\n","        if meme_file.suffix.lower() not in TRACKED_EXTS or not meme_file.is_file():\n","            continue\n","\n","        memes.append({\n","            \"file\": str(meme_file),\n","            \"filemtime\": get_file_timestamp(meme_file),   # dt obj\n","            \"metadata\": {\n","                k: str(meme_file.with_name(meme_file.name + suffix))\n","                for k, suffix in {\n","                    \"tesseract-ocr\": \".txt\",\n","                    \"llama-3.2-vision\": \".llama-3.2-vision.txt\"\n","                }.items()\n","                if meme_file.with_name(meme_file.name + suffix).exists()\n","            }\n","        })\n","\n","    # newest first\n","    memes.sort(key=lambda m: m[\"filemtime\"], reverse=True)\n","\n","    # re-index so 1 == newest\n","    return {i: _serialise(meme) for i, meme in enumerate(memes, 1)}\n","\n","def _serialise(meme: dict) -> dict:\n","    \"\"\"Convert dt ‚Üí iso-string without microseconds so JSON dump works.\"\"\"\n","    meme = meme.copy()\n","    meme[\"filemtime\"] = meme[\"filemtime\"]\n","    return meme\n","\n","def build_master_json():\n","    \"\"\"Build the master JSON file with all topics and all memes\"\"\"\n","    master_dict = {}\n","\n","    for topic in get_topics():\n","        master_dict[topic] = process_topic(topic)\n","\n","    # Sort each topic's memes by filemtime descending\n","    for topic, memes in master_dict.items():\n","        sorted_memes = dict(sorted(memes.items(), key=lambda item: item[1]['filemtime'], reverse=True))\n","        master_dict[topic] = sorted_memes\n","\n","    return master_dict\n","\n","master_json_data = build_master_json()\n","\n","\n","## Save JSON File\n","\n","with open('memes.json', 'w') as json_file:\n","    json.dump(master_json_data, json_file, indent=4)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Generate a markdown file for each meme"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from pathlib import Path\n","\n","META_ORDER = [\"llama-3.2-vision\", \"first-seen\", \"tesseract\"]\n","META_SUFFIXES = {\n","    \"gemma3-27b-vision\": \".gemma3-27b-vision.txt\",\n","    \"llama-3.2-vision\": \".llama3.2-vision.txt\",\n","    \"tesseract\": \".txt\",\n","    \"first-seen\": \".first-seen.txt\",\n","}\n","\n","def create_markdown_files(root=MEMES_ROOT):\n","    root = Path(root)\n","    for meme in root.rglob('*'):\n","        if meme.suffix.lower() not in TRACKED_EXTS or not meme.is_file():\n","            continue\n","\n","        md_file = meme.with_name(meme.name + '.md')\n","        lines = [\n","            '---\\n',\n","            'layout: meme\\n',\n","            f'title: {meme.name}\\n',\n","            f'category: {meme.parent.name}\\n',\n","            '---\\n\\n',\n","        ]\n","\n","        lines.append(f'<div markdown=\"0\">')\n","        if meme.suffix.lower() in IMAGE_EXTS:\n","            lines.append(f'<a href=\"{meme.name}\"><img class=\"photo\" src=\"{meme.name}\" /></a>\\n\\n')\n","        else:\n","            lines.append(f'[Download {meme.name}]({meme.name})\\n')\n","\n","        for meta in META_ORDER:\n","            \n","            meta_path = meme.with_name(meme.name + META_SUFFIXES[meta])\n","            \n","            if meta_path.exists():\n","                content = read_text_multi(meta_path).strip()\n","                lines.append(f'<h2>{meta}</h2>\\n')\n","\n","                if meta == \"gemma3-27b-vision\":\n","                    lines.append(f'<p title=\"Gemma3-27B is a really good model.\">{content}</p>\\n\\n')\n","                if meta == \"llama-3.2-vision\":\n","                    lines.append(f'<p title=\"Llama-3.2-11B is a really good model that probably gets the visual details right but doesn\\'t understand literary or media references, and often fails to accurately represent the physical arrangement of objects and the implied relationships between the objects.\">{escape_entities(content)}</p>\\n\\n')\n","                elif meta == \"first-seen\":\n","                    lines.append(f'<p title=\"Because Git doesn\\'t preserve file modification times, this metadata file contains the file\\'s modification time when it was added to the library.\">{escape_entities(content)}</p>\\n\\n')\n","                elif meta == \"tesseract\":\n","                    lines.append(f'<p title=\"Tesseract is often terrible and just gives a lot of nonsense characters, but it used to be the state of the art, and usually it is better at correctly representing text than llama-3.2-vision-11b.\">{escape_entities(content)}</p>\\n\\n')\n","\n","\n","                \n","\n","        lines.append('</div>\\n\\n')\n","        md_file.write_text(''.join(lines), encoding='utf-8')\n","\n","create_markdown_files()\n"]},{"cell_type":"markdown","metadata":{},"source":["# Generate new markdown index files for each category directory"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_category_indexes(root=MEMES_ROOT):\n","    root = Path(root)\n","    for category in root.iterdir():\n","        if not category.is_dir():\n","            continue\n","        index_md = category / 'index.md'\n","        entries = []\n","        for meme in category.iterdir():\n","            if meme.suffix.lower() not in TRACKED_EXTS or not meme.is_file():\n","                continue\n","            fs_path = meme.with_name(meme.name + META_SUFFIXES['first-seen'])\n","            llama_path = meme.with_name(meme.name + META_SUFFIXES['llama-3.2-vision'])\n","            gemma_path = meme.with_name(meme.name + META_SUFFIXES['gemma3-27b-vision'])\n","            first_seen = read_text_multi(fs_path).strip() if fs_path.exists() else ''\n","            llama = read_text_multi(llama_path).strip() if llama_path.exists() else ''\n","            gemma = read_text_multi(gemma_path).strip() if gemma_path.exists() else ''\n","            html = meme.name + '.html'\n","            cat = category.name\n","            entries.append((first_seen, meme.name, html, llama, cat, gemma))\n","        entries.sort(key=lambda e: e[0], reverse=True)\n","        lines = [\n","            '---\\n',\n","            'layout: category\\n',\n","            f'title: \"{category.name}\"\\n',\n","            f'category: {category.name}\\n',\n","            '---\\n\\n',\n","        ]\n","        for fs, img, html, llama, cat, gemma in entries:\n","            llama = escape_entities(llama)\n","            lines.append(f'<div markdown=\"0\">')\n","            lines.append(f'<div class=\"card mb-4\" data-category=\"{cat}\" data-pubdate=\"{fs}\">')\n","            lines.append(f'  <a href=\"{html}\"><img class=\"card-img-top\" loading=\"lazy\" src=\"{img}\" alt=\"{llama}\" /></a>')\n","            lines.append('  <div class=\"card-body\">')\n","            lines.append(f'<p><a href=\\\"memes/{cat}/index.html\\\">{cat}</a></p>\\n')\n","            if fs:\n","                lines.append(f'    <h4>First Seen:</h4><p class=\"card-text text-muted small firstseen\">{fs}</p>')\n","            if gemma:\n","                lines.append(f'    <h4>Gemma-3-27b\\'s Take:</h4><p class=\"card-text text-muted small gemma-output\">{gemma}</p>')\n","            if llama:\n","                lines.append(f'    <h4>Llama-3.2-11b\\'s Take:</h4><p class=\"card-text text-muted small llama-output\">{llama}</p>')\n","            lines.append('  </div>')\n","            lines.append('</div>\\n\\n')\n","        index_md.write_text(''.join(lines), encoding='utf-8')\n","\n","create_category_indexes()"]},{"cell_type":"markdown","metadata":{},"source":["# Generate main index markdown"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_main_index(root=MEMES_ROOT, out_file=Path(\"index.md\")):\n","    root = Path(root)\n","    entries = []\n","    for category in root.iterdir():\n","        if not category.is_dir():\n","            continue\n","        for meme in category.iterdir():\n","            if meme.suffix.lower() not in TRACKED_EXTS or not meme.is_file():\n","                continue\n","            fs_path = meme.with_name(meme.name + META_SUFFIXES['first-seen'])\n","            llama_path = meme.with_name(meme.name + META_SUFFIXES['llama-3.2-vision'])\n","            gemma_path = meme.with_name(meme.name + META_SUFFIXES['gemma3-27b-vision'])\n","            first_seen = read_text_multi(fs_path).strip() if fs_path.exists() else ''\n","            llama = read_text_multi(llama_path).strip() if llama_path.exists() else ''\n","            gemma = read_text_multi(gemma_path).strip() if gemma_path.exists() else ''            \n","            html = f\"memes/{category.name}/{meme.name}.html\"\n","            img  = f\"memes/{category.name}/{meme.name}\"\n","            cat = category.name\n","            entries.append((first_seen, category.name, img, html, llama, cat, gemma))\n","    entries.sort(key=lambda e: e[0], reverse=True)\n","    lines = [\n","        '---\\n',\n","        'layout: homepage\\n',\n","        'title: \"memes.cjtrowbridge.com\"\\n',\n","        '---\\n\\n',\n","    ]\n","    for fs, cat, img, html, llama, cat, gemma in entries:\n","        llama = escape_entities(llama)\n","        lines.append(f'<div markdown=\"0\">')\n","        lines.append(f'<div class=\"card mb-4\" data-category=\"{cat}\" data-pubdate=\"{fs}\">')\n","        lines.append(f'  <a href=\"{html}\"><img class=\"card-img-top\" loading=\"lazy\" src=\"{img}\" alt=\"{llama}\" /></a>')\n","        lines.append('  <div class=\"card-body\">')\n","        lines.append(f'<p><a href=\\\"memes/{cat}/index.html\\\">{cat}</a></p>\\n')\n","        if fs:\n","            lines.append(f'    <h4>First Seen:</h4><p class=\"card-text text-muted small firstseen\">{fs}</p>')\n","        if gemma:\n","            lines.append(f'    <h4>Gemma-3-27b\\'s Take:</h4><p class=\"card-text text-muted small gemma-output\"><b>Gemma3-27B:</b> {gemma}</p>')\n","        if llama:\n","            lines.append(f'    <h4>Llama-3.2-11b\\'s Take:</h4><p class=\"card-text text-muted small llama-output\"><b>Llama-3.2-11B:</b> {llama}</p>')\n","        lines.append('  </div>')\n","        lines.append('</div>\\n\\n')\n","    Path(out_file).write_text(''.join(lines), encoding='utf-8')\n","\n","create_main_index()\n"]},{"cell_type":"markdown","metadata":{},"source":["# Generate Sidebar"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def generate_sidebar(root=MEMES_ROOT, out_file=\"_includes/categories.html\"):\n","    root = Path(root)\n","    categories = sorted(p.name for p in root.iterdir() if p.is_dir())\n","    lines = ['<h2>Meme Categories:</h2>\\n', '<ul>\\n']\n","    for cat in categories:\n","        cat_path = root / cat\n","        count = sum(1 for f in cat_path.iterdir() if f.is_file() and f.suffix.lower() in TRACKED_EXTS)\n","        new_count = 0\n","        for f in cat_path.iterdir():\n","            if f.is_file() and f.suffix.lower() in TRACKED_EXTS:\n","                first_seen = f.with_suffix(f.suffix + '.first-seen.txt')\n","                if first_seen.exists():\n","                    ts = first_seen.read_text().strip()\n","                    dt = datetime.fromisoformat(ts)\n","                    if datetime.now(timezone.utc) - dt <= timedelta(days=14):\n","                        new_count += 1\n","        new_part = f' <span style=\"color:red\">({new_count} New)</span>' if new_count else ''\n","        lines.append(f'  <li><a href=\"/memes/{cat}/index.html\">{cat}</a> ({count}){new_part}</li>\\n')\n","    lines.append('</ul>\\n')\n","    Path(out_file).write_text(''.join(lines), encoding='utf-8')\n","\n","generate_sidebar(out_file=\"_includes/categories.html\")"]},{"cell_type":"markdown","metadata":{},"source":["# Build like jeckyll"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import sys, subprocess, importlib, textwrap\n","from pathlib import Path\n","\n","REPO_ROOT = Path.cwd()\n","MD_EXT = \".md\"\n","HTML_EXT = \".html\"\n","\n","PKGS = {\"python-frontmatter\": \"frontmatter\",\n","        \"markdown\": \"markdown\",\n","        \"python-liquid\": \"liquid\"}\n","\n","def _pip_install(pkg):\n","    print(f\"‚ñ∂ installing {pkg} ‚Ä¶\")\n","    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", pkg])\n","\n","for pip_name, mod_name in PKGS.items():\n","    try:\n","        importlib.import_module(mod_name)\n","    except ModuleNotFoundError:\n","        _pip_install(pip_name)\n","\n","import frontmatter, markdown\n","try:\n","    import liquid\n","    HAVE_LIQUID = True\n","    env = liquid.Environment(loader=liquid.FileSystemLoader(\"_includes\"))\n","except ModuleNotFoundError:\n","    HAVE_LIQUID = False\n","\n","LAYOUT_DIR = REPO_ROOT / \"_layout\"\n","\n","DEFAULT_LAYOUT = LAYOUT_DIR / \"default.html\"\n","DEFAULT_TEMPLATE = DEFAULT_LAYOUT.read_text(encoding=\"utf-8\")\n","\n","\n","def render_html(md_path: Path) -> str:\n","    post = frontmatter.load(md_path)\n","    md_html = markdown.markdown(\n","        post.content,\n","        extensions=[\"extra\", \"codehilite\", \"toc\", \"tables\", \"sane_lists\"],\n","    )\n","    if HAVE_LIQUID:\n","        md_html = env.from_string(md_html).render(**post.metadata)\n","\n","    layout_name = post.get(\"layout\") or \"default\"\n","    layout_path = LAYOUT_DIR / f\"{layout_name}.html\"\n","    if layout_path.exists():\n","        template = layout_path.read_text(encoding=\"utf-8\")\n","    else:\n","        template = DEFAULT_TEMPLATE\n","\n","    title = post.get(\"title\") or md_path.stem\n","    category = post.get(\"category\") or \"uncategorized\"\n","    html = template.replace(\"{title}\", str(title))\n","    html = html.replace(\"{content}\", md_html)\n","    html = html.replace(\"{category}\", str(category))\n","    if HAVE_LIQUID:\n","        html = env.from_string(html).render(**post.metadata)\n","    return html\n","\n","converted, skipped = 0, 0\n","for md_file in REPO_ROOT.rglob(f\"*{MD_EXT}\"):\n","    if md_file.parts[0].startswith((\".venv\", \".git\", \".ipynb_checkpoints\", \"_site\")):\n","        continue\n","    html_path = md_file.with_suffix(HTML_EXT)\n","    if html_path.exists() and html_path.stat().st_mtime >= md_file.stat().st_mtime:\n","        skipped += 1\n","        continue\n","    html_path.write_text(render_html(md_file), encoding=\"utf-8\")\n","    converted += 1\n","    print(\"‚úì\", html_path.relative_to(REPO_ROOT))\n","print(f\"\\nüéâ  Done. {converted} file(s) converted, {skipped} up-to-date.\")\n"]},{"cell_type":"markdown","metadata":{},"source":["# Generate missing llama-3.2-vision.txt files\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import base64, requests, textwrap, time\n","from pathlib import Path\n","from requests.exceptions import RequestException\n","\n","MODEL_NAME   = \"llama3.2-vision:11b\"\n","OLLAMA_URL   = \"http://docker-ai:11434/api/generate\"\n","PROMPT       = (\n","    \"In 2-3 sentences, describe this meme for someone who cannot see it. \"\n","    \"Include any text that appears in the image.\"\n",")\n","\n","\n","MAX_RETRIES  = 3        # total attempts per image\n","INITIAL_WAIT = 5        # seconds before first retry (doubles each time)\n","\n","def _meta_path(img: Path) -> Path:\n","    return img.with_name(f\"{img.name}.llama3.2-vision.txt\")\n","\n","def _summarise_image(img: Path) -> str:\n","    \"\"\"Call Ollama with retries; raise after MAX_RETRIES failures.\"\"\"\n","    img_b64  = base64.b64encode(img.read_bytes()).decode()\n","    payload  = {\n","        \"model\": MODEL_NAME,\n","        \"prompt\": PROMPT,\n","        \"stream\": False,\n","        \"images\": [img_b64],\n","    }\n","    for attempt in range(1, MAX_RETRIES + 1):\n","        try:\n","            r = requests.post(OLLAMA_URL, json=payload, timeout=300)\n","            r.raise_for_status()\n","            summary = r.json().get(\"response\", \"\").strip()\n","            if not summary:\n","                raise ValueError(\"API returned empty 'response'\")\n","            return summary\n","        except (RequestException, ValueError) as err:\n","            wait = INITIAL_WAIT * 2 ** (attempt - 1)\n","            print(f\"[{img.name}] attempt {attempt}/{MAX_RETRIES} failed: {err}\")\n","            if attempt < MAX_RETRIES:\n","                print(f\"   ‚Üí retrying in {wait}s ‚Ä¶\")\n","                time.sleep(wait)\n","            else:\n","                raise  # bubbled up to main loop\n","\n","def create_all_summaries(root=MEMES_ROOT):\n","    root = Path(root)\n","    images = [\n","        img for img in root.rglob('*')\n","        if img.suffix.lower() in IMAGE_EXTS and not _meta_path(img).exists()\n","    ]\n","    total = len(images)\n","    runs = []\n","    skipped = made = 0\n","    for idx, img in enumerate(images, 1):\n","        try:\n","            t0 = time.perf_counter()\n","            summary = _summarise_image(img)\n","            elapsed = time.perf_counter() - t0\n","            runs.append([idx, elapsed])\n","            meta = _meta_path(img)\n","            meta.write_text(summary + \"\\n\", encoding='utf-8')\n","            made += 1\n","            print(f\"\\n‚üπ  {img.relative_to(root)}\")\n","            print(textwrap.fill(summary, width=88))\n","            print(f\"‚Äî saved to {meta.name} ‚Äî\")\n","            avg = sum(r[1] for r in runs) / len(runs)\n","            remaining = total - idx\n","            percent = idx / total * 100 if total else 100\n","            eta = remaining * avg\n","            print(f\"{percent:.1f}% complete, ~{format_duration(eta)} remaining\")\n","        except Exception as e:\n","            skipped += 1\n","            print(f\"[skip] {img.relative_to(root)} ‚Üí {e}\")\n","    print(f\"\\n‚úì Done. {made} files written, {skipped} skipped after retries.\")\n","    return runs\n","\n","create_all_summaries()\n"]},{"cell_type":"markdown","metadata":{},"source":["# Generate missing gemma3-27b-vision.txt files"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["import base64, requests, textwrap, time\n","from pathlib import Path\n","from requests.exceptions import RequestException\n","\n","MODEL_NAME   = \"gemma3:27b\"\n","OLLAMA_URL   = \"http://docker-ai:11434/api/generate\"\n","PROMPT       = (\n","    \"Describe this in several sections with headings on the following topics (only if each topic applies): Visual Description, Foucauldian Genealogical Discourse Analysis, Critical Theory, Marxist Conflict Theory, Postmodernism, Queer Feminist Intersectional Analysis.\"\n",")\n","IMAGE_EXTS   = {\".jpeg\", \".jpg\", \".png\"}\n","\n","MAX_RETRIES  = 3        # total attempts per image\n","INITIAL_WAIT = 5        # seconds before first retry (doubles each time)\n","\n","def _meta_path(img: Path) -> Path:\n","    return img.with_name(f\"{img.name}.gemma3-27b-vision.txt\")\n","\n","def _summarise_image(img: Path) -> str:\n","    \"\"\"Call Ollama with retries; raise after MAX_RETRIES failures.\"\"\"\n","    img_b64  = base64.b64encode(img.read_bytes()).decode()\n","    payload  = {\n","        \"model\": MODEL_NAME,\n","        \"prompt\": PROMPT,\n","        \"stream\": False,\n","        \"images\": [img_b64],\n","    }\n","    for attempt in range(1, MAX_RETRIES + 1):\n","        try:\n","            r = requests.post(OLLAMA_URL, json=payload, timeout=300)\n","            r.raise_for_status()\n","            summary = r.json().get('response', '').strip()\n","            if not summary:\n","                raise ValueError(\"API returned empty 'response'\")\n","            return summary\n","        except (RequestException, ValueError) as err:\n","            wait = INITIAL_WAIT * 2 ** (attempt - 1)\n","            print(f\"[{img.name}] attempt {attempt}/{MAX_RETRIES} failed: {err}\")\n","            if attempt < MAX_RETRIES:\n","                print(f\"   ‚Üí retrying in {wait}s ‚Ä¶\")\n","                time.sleep(wait)\n","            else:\n","                raise  # bubbled up to main loop\n","\n","def create_all_summaries(root=MEMES_ROOT):\n","    root = Path(root)\n","    images = [\n","        img for img in root.rglob('*')\n","        if img.suffix.lower() in IMAGE_EXTS and not _meta_path(img).exists()\n","    ]\n","    total = len(images)\n","    runs = []\n","    skipped = made = 0\n","    for idx, img in enumerate(images, 1):\n","        try:\n","            t0 = time.perf_counter()\n","            summary = _summarise_image(img)\n","            elapsed = time.perf_counter() - t0\n","            runs.append([idx, elapsed])\n","            meta = _meta_path(img)\n","            meta.write_text(summary + \"\\n\", encoding='utf-8')\n","            made += 1\n","            print(f\"\\n‚üπ  {img.relative_to(root)}\")\n","            print(textwrap.fill(summary, width=88))\n","            print(f\"‚Äî saved to {meta.name} ‚Äî\")\n","            avg = sum(r[1] for r in runs) / len(runs)\n","            remaining = total - idx\n","            percent = idx / total * 100 if total else 100\n","            eta = remaining * avg\n","            print(f\"{percent:.1f}% complete, ~{format_duration(eta)} remaining\")\n","        except Exception as e:\n","            skipped += 1\n","            print(f\"[skip] {img.relative_to(root)} ‚Üí {e}\")\n","    print(f\"\\n‚úì Done. {made} files written, {skipped} skipped after retries.\")\n","    return runs\n","\n","create_all_summaries()\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":4}
