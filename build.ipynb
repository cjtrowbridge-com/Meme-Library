{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memes Library Builder\n",
    "\n",
    "This library contains tens of thousands of memes organized in hundreds of folders by topic. This notebook builds the master json file which contains a list of all the topics, all the memes in each topic, and a list of any metadata associated with each meme.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Libraries\n",
    "\n",
    "import os\n",
    "import json\n",
    "from glob import glob",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Constants\n",
    "\n",
    "MEMES_ROOT = Path('memes')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create missing first-seen files\n",
    "\n",
    "Iterate recursively through all the subdirectories of the ./memes folder and for any file with one of the following extensions, check if it already has a file with the same name in the same directory but appended with first-seen.txt. So for example meme.jpg meansthere should also be a file called meme.jpg.first-seen.txt  \n",
    "\n",
    "If not, create a new file containing the file modification time as a python datetime. This file should have the same name but appended with first-seen.txt. So for example meme.jpg means we need to create a file called meme.jpg.first-seen.txt containing the python datetime of the modification time of the meme.jpg file.  \n",
    "\n",
    "- .gif\n",
    "- .jfif\n",
    "- .jpeg\n",
    "- .jpg\n",
    "- .mp4\n",
    "- .png\n",
    "- .svg\n",
    "- .webp\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "\n",
    "TRACKED_EXTS = {\n",
    "    \".gif\", \".jfif\", \".jpeg\", \".jpg\",\n",
    "    \".mp4\", \".png\", \".svg\", \".webp\",\n",
    "}\n",
    "\n",
    "def ensure_first_seen_files(root: Path, exts: set[str]) -> dict[str, int]:\n",
    "    created = 0\n",
    "    skipped = 0\n",
    "\n",
    "    for file in root.rglob(\"*\"):\n",
    "        if file.suffix.lower() not in exts or not file.is_file():\n",
    "            continue\n",
    "\n",
    "        meta_path = file.with_name(file.name + \".first-seen.txt\")\n",
    "\n",
    "        if meta_path.exists():\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        # \u25b6 grab mtime and convert to UTC datetime\n",
    "        mod_time = datetime.fromtimestamp(file.stat().st_mtime,\n",
    "                                          tz=timezone.utc)\n",
    "        # \u25b6 write ISO-8601 string\n",
    "        meta_path.write_text(mod_time.isoformat())\n",
    "\n",
    "        created += 1\n",
    "\n",
    "    return {\"created\": created, \"skipped\": skipped}\n",
    "\n",
    "summary = ensure_first_seen_files(MEMES_ROOT, TRACKED_EXTS)\n",
    "print(f\"First-seen files created: {summary['created']}\")\n",
    "print(f\"Already present / skipped : {summary['skipped']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Build the master memes.json file\n",
    "\n",
    "The memes are organized like so;\n",
    "/memes/Topic 1\n",
    "/memes/Topic 2\n",
    "\n",
    "Memes can be images or videos. Assume all the common file extensions will be present. For each meme, a number of metadata files may be present. These should be included if present.\n",
    "\n",
    "For example;\n",
    "memefilename.jpg\n",
    "memefilename.jpg.txt <- Canonical tesseract-OCR of the meme. Might be nonsense. Probably we won't need this but it's there, so lets include it in the json file.\n",
    "memefilename.jpg.llama-3.2-vision.txt <- High quality transformer analysis of the image, containing detailed explanation of the visual elements of the image, including any text, but probably lacking an awareness of any social context or any relationship to current events.\n",
    "\n",
    "Example output:\n",
    "\n",
    "'Topic 1' => {\n",
    "    1 => {\n",
    "        'file' => 'memes/topic/filename.jpg',\n",
    "        'filemtime' => 'date the file was last modified',\n",
    "        'metadata' => {\n",
    "            'tesseract-ocr' => 'memes/topic/filename.jpg.txt',\n",
    "            'llama-3.2-vision' => 'memes/topic/filename.jpg.llama-3.2-vision.txt'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "The list of memes in each topic must be ordered by filemtime descending, such that the most recently added item is number 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def get_file_timestamp(file: Path) -> datetime:\n",
    "    \n",
    "    file = Path(file)\n",
    "    \n",
    "    meta_path = file.with_name(file.name + \".first-seen.txt\")\n",
    "\n",
    "    if meta_path.exists():\n",
    "        # Read the timestamp from first-seen.txt\n",
    "        mod_time_str = meta_path.read_text().strip()\n",
    "        return mod_time_str\n",
    "    else:\n",
    "        # Fallback to current modification time\n",
    "        return datetime.fromtimestamp(file.stat().st_mtime, tz=timezone.utc).isoformat()\n",
    "    \n",
    "def get_topics():\n",
    "    \"\"\"Return list of topic folders in the memes directory\"\"\"\n",
    "    return [p.name for p in MEMES_ROOT.iterdir() if p.is_dir()]\n",
    "\n",
    "def process_topic(topic: str) -> dict[int, dict]:\n",
    "    topic_path = Path(MEMES_ROOT) / topic\n",
    "    memes: list[dict] = []\n",
    "\n",
    "    for meme_file in topic_path.iterdir():\n",
    "        if meme_file.suffix.lower() not in TRACKED_EXTS or not meme_file.is_file():\n",
    "            continue\n",
    "\n",
    "        memes.append({\n",
    "            \"file\": str(meme_file),\n",
    "            \"filemtime\": get_file_timestamp(meme_file),   # dt obj\n",
    "            \"metadata\": {\n",
    "                k: str(meme_file.with_name(meme_file.name + suffix))\n",
    "                for k, suffix in {\n",
    "                    \"tesseract-ocr\": \".txt\",\n",
    "                    \"llama-3.2-vision\": \".llama-3.2-vision.txt\"\n",
    "                }.items()\n",
    "                if meme_file.with_name(meme_file.name + suffix).exists()\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # newest first\n",
    "    memes.sort(key=lambda m: m[\"filemtime\"], reverse=True)\n",
    "\n",
    "    # re-index so 1 == newest\n",
    "    return {i: _serialise(meme) for i, meme in enumerate(memes, 1)}\n",
    "\n",
    "def _serialise(meme: dict) -> dict:\n",
    "    \"\"\"Convert dt \u2192 iso-string without microseconds so JSON dump works.\"\"\"\n",
    "    meme = meme.copy()\n",
    "    meme[\"filemtime\"] = meme[\"filemtime\"]\n",
    "    return meme\n",
    "\n",
    "def build_master_json():\n",
    "    \"\"\"Build the master JSON file with all topics and all memes\"\"\"\n",
    "    master_dict = {}\n",
    "\n",
    "    for topic in get_topics():\n",
    "        master_dict[topic] = process_topic(topic)\n",
    "\n",
    "    # Sort each topic's memes by filemtime descending\n",
    "    for topic, memes in master_dict.items():\n",
    "        sorted_memes = dict(sorted(memes.items(), key=lambda item: item[1]['filemtime'], reverse=True))\n",
    "        master_dict[topic] = sorted_memes\n",
    "\n",
    "    return master_dict\n",
    "\n",
    "master_json_data = build_master_json()\n",
    "\n",
    "\n",
    "## Save JSON File\n",
    "\n",
    "with open('memes.json', 'w') as json_file:\n",
    "    json.dump(master_json_data, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate missing llama-3.2-vision.txt files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64, requests, textwrap, time\n",
    "from pathlib import Path\n",
    "from requests.exceptions import RequestException\n",
    "\n",
    "MODEL_NAME   = \"llama3.2-vision:11b\"\n",
    "OLLAMA_URL   = \"http://docker-ai:11434/api/generate\"\n",
    "PROMPT       = (\n",
    "    \"In 2-3 sentences, describe this meme for someone who cannot see it. \"\n",
    "    \"Include any text that appears in the image.\"\n",
    ")\n",
    "IMAGE_EXTS   = {\".gif\", \".jfif\", \".jpeg\", \".jpg\", \".png\", \".svg\", \".webp\"}\n",
    "\n",
    "MAX_RETRIES  = 3        # total attempts per image\n",
    "INITIAL_WAIT = 5        # seconds before first retry (doubles each time)\n",
    "\n",
    "def _meta_path(img: Path) -> Path:\n",
    "    return img.with_name(f\"{img.name}.llama3.2-vision.txt\")\n",
    "\n",
    "def _summarise_image(img: Path) -> str:\n",
    "    \"\"\"Call Ollama with retries; raise after MAX_RETRIES failures.\"\"\"\n",
    "    img_b64  = base64.b64encode(img.read_bytes()).decode()\n",
    "    payload  = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"prompt\": PROMPT,\n",
    "        \"stream\": False,\n",
    "        \"images\": [img_b64],\n",
    "    }\n",
    "\n",
    "    for attempt in range(1, MAX_RETRIES + 1):\n",
    "        try:\n",
    "            r = requests.post(OLLAMA_URL, json=payload, timeout=300)\n",
    "            r.raise_for_status()\n",
    "            summary = r.json().get(\"response\", \"\").strip()\n",
    "            if not summary:\n",
    "                raise ValueError(\"API returned empty 'response'\")\n",
    "            return summary\n",
    "\n",
    "        except (RequestException, ValueError) as err:\n",
    "            wait = INITIAL_WAIT * 2 ** (attempt - 1)\n",
    "            print(f\"[{img.name}] attempt {attempt}/{MAX_RETRIES} failed: {err}\")\n",
    "            if attempt < MAX_RETRIES:\n",
    "                print(f\"   \u2192 retrying in {wait}s \u2026\")\n",
    "                time.sleep(wait)\n",
    "            else:\n",
    "                raise  # bubbled up to main loop\n",
    "\n",
    "def create_all_summaries(root=MEMES_ROOT):\n",
    "    skipped, made = 0, 0\n",
    "    for img in Path(root).rglob(\"*\"):\n",
    "        if img.suffix.lower() not in IMAGE_EXTS or _meta_path(img).exists():\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            summary = _summarise_image(img)\n",
    "            meta    = _meta_path(img)\n",
    "            meta.write_text(summary + \"\\n\", encoding=\"utf-8\")\n",
    "            made += 1\n",
    "\n",
    "            print(f\"\\n\u27f9  {img.relative_to(root)}\")\n",
    "            print(textwrap.fill(summary, width=88))\n",
    "            print(f\"\u2014 saved to {meta.name} \u2014\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            skipped += 1\n",
    "            print(f\"[skip] {img.relative_to(root)} \u2192 {e}\")\n",
    "\n",
    "    print(f\"\\n\u2713 Done. {made} files written, {skipped} skipped after retries.\")\n",
    "\n",
    "create_all_summaries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a markdown file for each meme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MEMES_ROOT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      3\u001b[39m META_ORDER = [\u001b[33m'\u001b[39m\u001b[33mllama-3.2-vision\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtesseract\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfirst-seen\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      4\u001b[39m META_SUFFIXES = {\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mllama-3.2-vision\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33m.llama-3.2-vision.txt\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      6\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtesseract\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33m.txt\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      7\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfirst-seen\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33m.first-seen.txt\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      8\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_markdown_files\u001b[39m(root=\u001b[43mMEMES_ROOT\u001b[49m):\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m meme \u001b[38;5;129;01min\u001b[39;00m Path(root).rglob(\u001b[33m'\u001b[39m\u001b[33m*\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     12\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m meme.suffix.lower() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m TRACKED_EXTS \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m meme.is_file():\n",
      "\u001b[31mNameError\u001b[39m: name 'MEMES_ROOT' is not defined"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "META_ORDER = [\"llama-3.2-vision\", \"tesseract\", \"first-seen\"]\n",
    "META_SUFFIXES = {\n",
    "    \"llama-3.2-vision\": \".llama-3.2-vision.txt\",\n",
    "    \"tesseract\": \".txt\",\n",
    "    \"first-seen\": \".first-seen.txt\",\n",
    "}\n",
    "\n",
    "def create_markdown_files(root=MEMES_ROOT):\n",
    "    root = Path(root)\n",
    "    for meme in root.rglob('*'):\n",
    "        if meme.suffix.lower() not in TRACKED_EXTS or not meme.is_file():\n",
    "            continue\n",
    "\n",
    "        md_file = meme.with_name(meme.name + '.md')\n",
    "        lines = [\n",
    "            '---\n",
    "',\n",
    "            'layout: default\n",
    "',\n",
    "            f'title: {meme.name}\n",
    "',\n",
    "            '---\n",
    "\n",
    "',\n",
    "        ]\n",
    "\n",
    "        if meme.suffix.lower() in IMAGE_EXTS:\n",
    "            lines.append(f'<a href=\"{meme.name}\"><img class=\"photo\" src=\"{meme.name}\" /></a>\n",
    "\n",
    "')\n",
    "        else:\n",
    "            lines.append(f'[Download {meme.name}]({meme.name})\n",
    "\n",
    "')\n",
    "\n",
    "        for meta in META_ORDER:\n",
    "            meta_path = meme.with_name(meme.name + META_SUFFIXES[meta])\n",
    "            if meta_path.exists():\n",
    "                content = meta_path.read_text().strip()\n",
    "                lines.append(f'<h2>{meta}</h2>\n",
    "<p>{content}</p>\n",
    "')\n",
    "\n",
    "        md_file.write_text(''.join(lines), encoding='utf-8')\n",
    "\n",
    "create_markdown_files()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate new markdown files for each category directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
