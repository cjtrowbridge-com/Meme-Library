{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Memes Library Builder\n","\n","This library contains tens of thousands of memes organized in hundreds of folders by topic. This notebook builds the master json file which contains a list of all the topics, all the memes in each topic, and a list of any metadata associated with each meme.\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["## Import Libraries\n","\n","import os\n","import json\n","from glob import glob\n","from pathlib import Path\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["## Define Constants\n","\n","MEMES_ROOT = Path('memes')\n"]},{"cell_type":"markdown","metadata":{},"source":["# Create missing first-seen files\n","\n","Iterate recursively through all the subdirectories of the ./memes folder and for any file with one of the following extensions, check if it already has a file with the same name in the same directory but appended with first-seen.txt. So for example meme.jpg meansthere should also be a file called meme.jpg.first-seen.txt  \n","\n","If not, create a new file containing the file modification time as a python datetime. This file should have the same name but appended with first-seen.txt. So for example meme.jpg means we need to create a file called meme.jpg.first-seen.txt containing the python datetime of the modification time of the meme.jpg file.  \n","\n","- .gif\n","- .jfif\n","- .jpeg\n","- .jpg\n","- .mp4\n","- .png\n","- .svg\n","- .webp\n","\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["First-seen files created: 2\n","Already present / skipped : 8406\n"]}],"source":["from pathlib import Path\n","from datetime import datetime, timezone\n","\n","\n","TRACKED_EXTS = {\n","    \".gif\", \".jfif\", \".jpeg\", \".jpg\",\n","    \".mp4\", \".png\", \".svg\", \".webp\",\n","}\n","\n","def ensure_first_seen_files(root: Path, exts: set[str]) -> dict[str, int]:\n","    created = 0\n","    skipped = 0\n","\n","    for file in root.rglob(\"*\"):\n","        if file.suffix.lower() not in exts or not file.is_file():\n","            continue\n","\n","        meta_path = file.with_name(file.name + \".first-seen.txt\")\n","\n","        if meta_path.exists():\n","            skipped += 1\n","            continue\n","\n","        # ▶ grab mtime and convert to UTC datetime\n","        mod_time = datetime.fromtimestamp(file.stat().st_mtime,\n","                                          tz=timezone.utc)\n","        # ▶ write ISO-8601 string\n","        meta_path.write_text(mod_time.isoformat())\n","\n","        created += 1\n","\n","    return {\"created\": created, \"skipped\": skipped}\n","\n","summary = ensure_first_seen_files(MEMES_ROOT, TRACKED_EXTS)\n","print(f\"First-seen files created: {summary['created']}\")\n","print(f\"Already present / skipped : {summary['skipped']}\")"]},{"cell_type":"markdown","metadata":{"tags":[]},"source":["# Build the master memes.json file\n","\n","The memes are organized like so;\n","/memes/Topic 1\n","/memes/Topic 2\n","\n","Memes can be images or videos. Assume all the common file extensions will be present. For each meme, a number of metadata files may be present. These should be included if present.\n","\n","For example;\n","memefilename.jpg\n","memefilename.jpg.txt <- Canonical tesseract-OCR of the meme. Might be nonsense. Probably we won't need this but it's there, so lets include it in the json file.\n","memefilename.jpg.llama-3.2-vision.txt <- High quality transformer analysis of the image, containing detailed explanation of the visual elements of the image, including any text, but probably lacking an awareness of any social context or any relationship to current events.\n","\n","Example output:\n","\n","'Topic 1' => {\n","    1 => {\n","        'file' => 'memes/topic/filename.jpg',\n","        'filemtime' => 'date the file was last modified',\n","        'metadata' => {\n","            'tesseract-ocr' => 'memes/topic/filename.jpg.txt',\n","            'llama-3.2-vision' => 'memes/topic/filename.jpg.llama-3.2-vision.txt'\n","        }\n","    }\n","}\n","\n","The list of memes in each topic must be ordered by filemtime descending, such that the most recently added item is number 1. "]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: html5lib in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.1)\n","Requirement already satisfied: six>=1.9 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from html5lib) (1.16.0)\n","Requirement already satisfied: webencodings in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from html5lib) (0.5.1)\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["! pip install html5lib\n","\n","# Helper functions\n","import html\n","\n","from html5lib.serializer import escape as _h5_escape\n","\n","# ──────────────────────────────────────────────────────────────────────\n","#  HTML-5 escaping  +  extra Liquid-safety for curly braces\n","# ──────────────────────────────────────────────────────────────────────\n","def escape_entities(text: str) -> str:\n","    \"\"\"\n","    • Encode &, <, >, quotes (html5lib default).\n","    • ALSO encode { and } so accidental `{{` / `{%` from OCR\n","      can’t be parsed by Liquid.\n","    • Collapse newlines to single spaces.\n","    \"\"\"\n","    return (\n","        _h5_escape(\n","            text,\n","            entities={\n","                '\"': \"&quot;\",      # keep attribute-safe quotes\n","                \"'\": \"&#x27;\",      # HTML5‐preferred apostrophe\n","                \"{\": \"&#123;\",      # <-- Liquid-safety\n","                \"}\": \"&#125;\",      # <-- Liquid-safety\n","            },\n","        )\n","        .replace(\"\\n\", \" \")\n","    )\n","\n","\n","def read_text_multi(path: Path, encodings=('utf-8', 'utf-8-sig', 'cp1252', 'latin-1')):\n","    \"Try multiple encodings and fall back to replacement.\"\n","    for enc in encodings:\n","        try:\n","            return path.read_text(encoding=enc)\n","        except UnicodeDecodeError:\n","            pass\n","    return path.read_text(encoding=encodings[0], errors='replace')\n","\n","def get_file_timestamp(file: Path) -> datetime:\n","    \n","    file = Path(file)\n","    \n","    meta_path = file.with_name(file.name + \".first-seen.txt\")\n","\n","    if meta_path.exists():\n","        # Read the timestamp from first-seen.txt\n","        mod_time_str = read_text_multi(meta_path).strip()\n","        return mod_time_str\n","    else:\n","        # Fallback to current modification time\n","        return datetime.fromtimestamp(file.stat().st_mtime, tz=timezone.utc).isoformat()\n","    \n","def get_topics():\n","    \"\"\"Return list of topic folders in the memes directory\"\"\"\n","    return [p.name for p in MEMES_ROOT.iterdir() if p.is_dir()]\n","\n","def process_topic(topic: str) -> dict[int, dict]:\n","    topic_path = Path(MEMES_ROOT) / topic\n","    memes: list[dict] = []\n","\n","    for meme_file in topic_path.iterdir():\n","        if meme_file.suffix.lower() not in TRACKED_EXTS or not meme_file.is_file():\n","            continue\n","\n","        memes.append({\n","            \"file\": str(meme_file),\n","            \"filemtime\": get_file_timestamp(meme_file),   # dt obj\n","            \"metadata\": {\n","                k: str(meme_file.with_name(meme_file.name + suffix))\n","                for k, suffix in {\n","                    \"tesseract-ocr\": \".txt\",\n","                    \"llama-3.2-vision\": \".llama-3.2-vision.txt\"\n","                }.items()\n","                if meme_file.with_name(meme_file.name + suffix).exists()\n","            }\n","        })\n","\n","    # newest first\n","    memes.sort(key=lambda m: m[\"filemtime\"], reverse=True)\n","\n","    # re-index so 1 == newest\n","    return {i: _serialise(meme) for i, meme in enumerate(memes, 1)}\n","\n","def _serialise(meme: dict) -> dict:\n","    \"\"\"Convert dt → iso-string without microseconds so JSON dump works.\"\"\"\n","    meme = meme.copy()\n","    meme[\"filemtime\"] = meme[\"filemtime\"]\n","    return meme\n","\n","def build_master_json():\n","    \"\"\"Build the master JSON file with all topics and all memes\"\"\"\n","    master_dict = {}\n","\n","    for topic in get_topics():\n","        master_dict[topic] = process_topic(topic)\n","\n","    # Sort each topic's memes by filemtime descending\n","    for topic, memes in master_dict.items():\n","        sorted_memes = dict(sorted(memes.items(), key=lambda item: item[1]['filemtime'], reverse=True))\n","        master_dict[topic] = sorted_memes\n","\n","    return master_dict\n","\n","master_json_data = build_master_json()\n","\n","\n","## Save JSON File\n","\n","with open('memes.json', 'w') as json_file:\n","    json.dump(master_json_data, json_file, indent=4)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Generate missing llama-3.2-vision.txt files\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","⟹  Anti-Reactionary\\503934731_1141673674666439_5565521421058569256_n.jpg\n","The meme features a photo of a man with a shaved head and a photo of a man with a\n","balding head. The text above the images reads, \"Norwegian tourist, 21, is barred from\n","entering the US after ICE guards find meme showing JD Vance with a bald head on his\n","phone.\" The meme is humorous because it implies that the man's bald head is so shocking\n","that it was enough to get him banned from entering the US.\n","— saved to 503934731_1141673674666439_5565521421058569256_n.jpg.llama3.2-vision.txt —\n","\n","\n","⟹  Anti-Reactionary\\512672534_24001203129511442_8292158899077143517_n.jpg\n","The meme features a tweet from KrangTNelson, an American singer-songwriter, that reads:\n","\"no no no you misunderstood. I said 'fuck YOUR feelings'. MY feelings are very important\n","and must be handled gently, like a tiny baby hummingbird.\" The tweet is a humorous\n","commentary on the importance of one's own feelings, using an exaggerated and absurd\n","analogy to convey the point. The tone is lighthearted and playful, with a touch of\n","sarcasm.\n","— saved to 512672534_24001203129511442_8292158899077143517_n.jpg.llama3.2-vision.txt —\n","\n","\n","✓ Done. 2 files written, 0 skipped after retries.\n"]}],"source":["import base64, requests, textwrap, time\n","from pathlib import Path\n","from requests.exceptions import RequestException\n","\n","MODEL_NAME   = \"llama3.2-vision:11b\"\n","OLLAMA_URL   = \"http://docker-ai:11434/api/generate\"\n","PROMPT       = (\n","    \"In 2-3 sentences, describe this meme for someone who cannot see it. \"\n","    \"Include any text that appears in the image.\"\n",")\n","IMAGE_EXTS   = {\".jpeg\", \".jpg\", \".png\"}\n","\n","MAX_RETRIES  = 3        # total attempts per image\n","INITIAL_WAIT = 5        # seconds before first retry (doubles each time)\n","\n","def _meta_path(img: Path) -> Path:\n","    return img.with_name(f\"{img.name}.llama3.2-vision.txt\")\n","\n","def _summarise_image(img: Path) -> str:\n","    \"\"\"Call Ollama with retries; raise after MAX_RETRIES failures.\"\"\"\n","    img_b64  = base64.b64encode(img.read_bytes()).decode()\n","    payload  = {\n","        \"model\": MODEL_NAME,\n","        \"prompt\": PROMPT,\n","        \"stream\": False,\n","        \"images\": [img_b64],\n","    }\n","\n","    for attempt in range(1, MAX_RETRIES + 1):\n","        try:\n","            r = requests.post(OLLAMA_URL, json=payload, timeout=300)\n","            r.raise_for_status()\n","            summary = r.json().get(\"response\", \"\").strip()\n","            if not summary:\n","                raise ValueError(\"API returned empty 'response'\")\n","            return summary\n","\n","        except (RequestException, ValueError) as err:\n","            wait = INITIAL_WAIT * 2 ** (attempt - 1)\n","            print(f\"[{img.name}] attempt {attempt}/{MAX_RETRIES} failed: {err}\")\n","            if attempt < MAX_RETRIES:\n","                print(f\"   → retrying in {wait}s …\")\n","                time.sleep(wait)\n","            else:\n","                raise  # bubbled up to main loop\n","\n","def create_all_summaries(root=MEMES_ROOT):\n","    skipped, made = 0, 0\n","    for img in Path(root).rglob(\"*\"):\n","        if img.suffix.lower() not in IMAGE_EXTS or _meta_path(img).exists():\n","            continue\n","\n","        try:\n","            summary = _summarise_image(img)\n","            meta    = _meta_path(img)\n","            meta.write_text(summary + \"\\n\", encoding=\"utf-8\")\n","            made += 1\n","\n","            print(f\"\\n⟹  {img.relative_to(root)}\")\n","            print(textwrap.fill(summary, width=88))\n","            print(f\"— saved to {meta.name} —\\n\")\n","\n","        except Exception as e:\n","            skipped += 1\n","            print(f\"[skip] {img.relative_to(root)} → {e}\")\n","\n","    print(f\"\\n✓ Done. {made} files written, {skipped} skipped after retries.\")\n","\n","create_all_summaries()"]},{"cell_type":"markdown","metadata":{},"source":["# Generate a markdown file for each meme"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["from pathlib import Path\n","\n","META_ORDER = [\"llama-3.2-vision\", \"first-seen\", \"tesseract\"]\n","META_SUFFIXES = {\n","    \"llama-3.2-vision\": \".llama3.2-vision.txt\",\n","    \"tesseract\": \".txt\",\n","    \"first-seen\": \".first-seen.txt\",\n","}\n","\n","def create_markdown_files(root=MEMES_ROOT):\n","    root = Path(root)\n","    for meme in root.rglob('*'):\n","        if meme.suffix.lower() not in TRACKED_EXTS or not meme.is_file():\n","            continue\n","\n","        md_file = meme.with_name(meme.name + '.md')\n","        lines = [\n","            '---\\n',\n","            'layout: meme\\n',\n","            f'title: {meme.name}\\n',\n","            f'category: {meme.parent.name}\\n',\n","            '---\\n\\n',\n","        ]\n","\n","        lines.append(f'<div markdown=\"0\">')\n","        if meme.suffix.lower() in IMAGE_EXTS:\n","            lines.append(f'<a href=\"{meme.name}\"><img class=\"photo\" src=\"{meme.name}\" /></a>\\n\\n')\n","        else:\n","            lines.append(f'[Download {meme.name}]({meme.name})\\n')\n","\n","        for meta in META_ORDER:\n","            \n","            meta_path = meme.with_name(meme.name + META_SUFFIXES[meta])\n","            \n","            if meta_path.exists():\n","                content = read_text_multi(meta_path).strip()\n","                lines.append(f'<h2>{meta}</h2>\\n')\n","\n","                if meta == \"llama-3.2-vision\":\n","                    lines.append(f'<p title=\"Llama-3.2-Vision-11B is a really good model that probably gets the visual details right but doesn\\'t understand literary or media references, and often fails to accurately represent the physical arrangement of objects and the implied relationships between the objects.\">{escape_entities(content)}</p>\\n\\n')\n","                elif meta == \"first-seen\":\n","                    lines.append(f'<p title=\"Because Git doesn\\'t preserve file modification times, this metadata file contains the file\\'s modification time when it was added to the library.\">{escape_entities(content)}</p>\\n\\n')\n","                elif meta == \"tesseract\":\n","                    lines.append(f'<p title=\"Tesseract is often terrible and just gives a lot of nonsense characters, but it used to be the state of the art, and usually it is better at correctly representing text than llama-3.2-vision-11b.\">{escape_entities(content)}</p>\\n\\n')\n","\n","\n","                \n","\n","        lines.append('</div>\\n\\n')\n","        md_file.write_text(''.join(lines), encoding='utf-8')\n","\n","create_markdown_files()\n"]},{"cell_type":"markdown","metadata":{},"source":["# Generate new markdown index files for each category directory"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def create_category_indexes(root=MEMES_ROOT):\n","    root = Path(root)\n","    for category in root.iterdir():\n","        if not category.is_dir():\n","            continue\n","        index_md = category / 'index.md'\n","        entries = []\n","        for meme in category.iterdir():\n","            if meme.suffix.lower() not in TRACKED_EXTS or not meme.is_file():\n","                continue\n","            fs_path = meme.with_name(meme.name + META_SUFFIXES['first-seen'])\n","            llama_path = meme.with_name(meme.name + META_SUFFIXES['llama-3.2-vision'])\n","            first_seen = read_text_multi(fs_path).strip() if fs_path.exists() else ''\n","            llama = read_text_multi(llama_path).strip() if llama_path.exists() else ''\n","            html = meme.name + '.html'\n","            cat = category.name\n","            entries.append((first_seen, meme.name, html, llama, cat))\n","        entries.sort(key=lambda e: e[0], reverse=True)\n","        lines = [\n","            '---\\n',\n","            'layout: category\\n',\n","            f'title: \"Category: {category.name}\"\\n',\n","            '---\\n\\n',\n","        ]\n","        for fs, img, html, llama, cat in entries:\n","            llama = escape_entities(llama)\n","            lines.append(f'<div markdown=\"0\">')\n","            lines.append(f'<div class=\"card mb-4\" data-category=\"{cat}\" data-pubdate=\"{fs}\">')\n","            lines.append(f'  <a href=\"{html}\"><img class=\"card-img-top\" loading=\"lazy\" src=\"{img}\" alt=\"{llama}\" /></a>')\n","            lines.append('  <div class=\"card-body\">')\n","            lines.append(f'<p><a href=\\\"memes/{cat}/index.html\\\">{cat}</a></p>\\n')\n","            if fs:\n","                lines.append(f'    <p class=\"card-text text-muted small\">{fs}</p>')\n","            if llama:\n","                lines.append(f'    <p class=\"card-text\">{llama}</p>')\n","            lines.append('  </div>')\n","            lines.append('</div>\\n\\n')\n","        index_md.write_text(''.join(lines), encoding='utf-8')\n","\n","create_category_indexes()"]},{"cell_type":"markdown","metadata":{},"source":["# Generate main index markdown"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def create_main_index(root=MEMES_ROOT, out_file=Path(\"index.md\")):\n","    root = Path(root)\n","    entries = []\n","    for category in root.iterdir():\n","        if not category.is_dir():\n","            continue\n","        for meme in category.iterdir():\n","            if meme.suffix.lower() not in TRACKED_EXTS or not meme.is_file():\n","                continue\n","            fs_path = meme.with_name(meme.name + META_SUFFIXES['first-seen'])\n","            llama_path = meme.with_name(meme.name + META_SUFFIXES['llama-3.2-vision'])\n","            first_seen = read_text_multi(fs_path).strip() if fs_path.exists() else ''\n","            llama = read_text_multi(llama_path).strip() if llama_path.exists() else ''\n","            html = f\"{category.name}/{meme.name}.html\"\n","            img  = f\"memes/{category.name}/{meme.name}\"\n","            cat = category.name\n","            entries.append((first_seen, category.name, img, html, llama, cat))\n","    entries.sort(key=lambda e: e[0], reverse=True)\n","    lines = [\n","        '---\\n',\n","        'layout: homepage\\n',\n","        'title: \"memes.cjtrowbridge.com\"\\n',\n","        '---\\n\\n',\n","    ]\n","    for fs, cat, img, html, llama, cat in entries:\n","        llama = escape_entities(llama)\n","        lines.append(f'<div markdown=\"0\">')\n","        lines.append(f'<div class=\"card mb-4\" data-category=\"{cat}\" data-pubdate=\"{fs}\">')\n","        lines.append(f'  <a href=\"{html}\"><img class=\"card-img-top\" loading=\"lazy\" src=\"{img}\" alt=\"{llama}\" /></a>')\n","        lines.append('  <div class=\"card-body\">')\n","        lines.append(f'<p><a href=\\\"memes/{cat}/index.html\\\">{cat}</a></p>\\n')\n","        if fs:\n","            lines.append(f'    <p class=\"card-text text-muted small\">{fs}</p>')\n","        #if llama:\n","            #lines.append(f'    <p class=\"card-text\">{llama}</p>')\n","        lines.append('  </div>')\n","        lines.append('</div>\\n\\n')\n","    Path(out_file).write_text(''.join(lines), encoding='utf-8')\n","\n","create_main_index()\n"]},{"cell_type":"markdown","metadata":{},"source":["# Build like jeckyll"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"ename":"KeyError","evalue":"'font-family'","output_type":"error","traceback":["\u001b[31m---------------------------------------------------------------------------\u001b[39m","\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)","\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 62\u001b[39m\n\u001b[32m     60\u001b[39m     skipped += \u001b[32m1\u001b[39m\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m html_path.write_text(\u001b[43mrender_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmd_file\u001b[49m\u001b[43m)\u001b[49m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     63\u001b[39m converted += \u001b[32m1\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✓\u001b[39m\u001b[33m\"\u001b[39m, html_path.relative_to(REPO_ROOT))\n","\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 52\u001b[39m, in \u001b[36mrender_html\u001b[39m\u001b[34m(md_path)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     50\u001b[39m     template = DEFAULT_TEMPLATE\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtemplate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtitle\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmd_path\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmd_html\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[31mKeyError\u001b[39m: 'font-family'"]}],"source":["import sys, subprocess, importlib, textwrap\n","from pathlib import Path\n","\n","REPO_ROOT = Path.cwd()\n","MD_EXT = \".md\"\n","HTML_EXT = \".html\"\n","\n","PKGS = {\"python-frontmatter\": \"frontmatter\",\n","        \"markdown\": \"markdown\",\n","        \"python-liquid\": \"liquid\"}\n","\n","def _pip_install(pkg):\n","    print(f\"▶ installing {pkg} …\")\n","    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", pkg])\n","\n","for pip_name, mod_name in PKGS.items():\n","    try:\n","        importlib.import_module(mod_name)\n","    except ModuleNotFoundError:\n","        _pip_install(pip_name)\n","\n","import frontmatter, markdown\n","try:\n","    import liquid\n","    HAVE_LIQUID = True\n","    env = liquid.Environment()\n","except ModuleNotFoundError:\n","    HAVE_LIQUID = False\n","\n","LAYOUT_DIR = REPO_ROOT / \"_layout\"\n","\n","DEFAULT_LAYOUT = LAYOUT_DIR / \"default.html\"\n","DEFAULT_TEMPLATE = DEFAULT_LAYOUT.read_text(encoding=\"utf-8\")\n","\n","\n","def render_html(md_path: Path) -> str:\n","    post = frontmatter.load(md_path)\n","    md_html = markdown.markdown(\n","        post.content,\n","        extensions=[\"extra\", \"codehilite\", \"toc\", \"tables\", \"sane_lists\"],\n","    )\n","    if HAVE_LIQUID:\n","        md_html = env.from_string(md_html).render(**post.metadata)\n","\n","    layout_name = post.get(\"layout\") or \"default\"\n","    layout_path = LAYOUT_DIR / f\"{layout_name}.html\"\n","    if layout_path.exists():\n","        template = layout_path.read_text(encoding=\"utf-8\")\n","    else:\n","        template = DEFAULT_TEMPLATE\n","\n","    return template.format(title=post.get(\"title\") or md_path.stem, content=md_html)\n","\n","converted, skipped = 0, 0\n","for md_file in REPO_ROOT.rglob(f\"*{MD_EXT}\"):\n","    if md_file.parts[0].startswith((\".venv\", \".git\", \".ipynb_checkpoints\", \"_site\")):\n","        continue\n","    html_path = md_file.with_suffix(HTML_EXT)\n","    if html_path.exists() and html_path.stat().st_mtime >= md_file.stat().st_mtime:\n","        skipped += 1\n","        continue\n","    html_path.write_text(render_html(md_file), encoding=\"utf-8\")\n","    converted += 1\n","    print(\"✓\", html_path.relative_to(REPO_ROOT))\n","print(f\"\\n🎉  Done. {converted} file(s) converted, {skipped} up-to-date.\")\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":4}
