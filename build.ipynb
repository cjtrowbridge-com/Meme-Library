{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memes Library Builder\n",
    "\n",
    "This library contains tens of thousands of memes organized in hundreds of folders by topic. This notebook builds the master json file which contains a list of all the topics, all the memes in each topic, and a list of any metadata associated with each meme.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Libraries\n",
    "\n",
    "import os\n",
    "import json\n",
    "from glob import glob\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Constants\n",
    "\n",
    "MEMES_ROOT = Path('memes')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create missing first-seen files\n",
    "\n",
    "Iterate recursively through all the subdirectories of the ./memes folder and for any file with one of the following extensions, check if it already has a file with the same name in the same directory but appended with first-seen.txt. So for example meme.jpg meansthere should also be a file called meme.jpg.first-seen.txt  \n",
    "\n",
    "If not, create a new file containing the file modification time as a python datetime. This file should have the same name but appended with first-seen.txt. So for example meme.jpg means we need to create a file called meme.jpg.first-seen.txt containing the python datetime of the modification time of the meme.jpg file.  \n",
    "\n",
    "- .gif\n",
    "- .jfif\n",
    "- .jpeg\n",
    "- .jpg\n",
    "- .mp4\n",
    "- .png\n",
    "- .svg\n",
    "- .webp\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First-seen files created: 0\n",
      "Already present / skipped : 8404\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "\n",
    "TRACKED_EXTS = {\n",
    "    \".gif\", \".jfif\", \".jpeg\", \".jpg\",\n",
    "    \".mp4\", \".png\", \".svg\", \".webp\",\n",
    "}\n",
    "\n",
    "def ensure_first_seen_files(root: Path, exts: set[str]) -> dict[str, int]:\n",
    "    created = 0\n",
    "    skipped = 0\n",
    "\n",
    "    for file in root.rglob(\"*\"):\n",
    "        if file.suffix.lower() not in exts or not file.is_file():\n",
    "            continue\n",
    "\n",
    "        meta_path = file.with_name(file.name + \".first-seen.txt\")\n",
    "\n",
    "        if meta_path.exists():\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        # ▶ grab mtime and convert to UTC datetime\n",
    "        mod_time = datetime.fromtimestamp(file.stat().st_mtime,\n",
    "                                          tz=timezone.utc)\n",
    "        # ▶ write ISO-8601 string\n",
    "        meta_path.write_text(mod_time.isoformat())\n",
    "\n",
    "        created += 1\n",
    "\n",
    "    return {\"created\": created, \"skipped\": skipped}\n",
    "\n",
    "summary = ensure_first_seen_files(MEMES_ROOT, TRACKED_EXTS)\n",
    "print(f\"First-seen files created: {summary['created']}\")\n",
    "print(f\"Already present / skipped : {summary['skipped']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Build the master memes.json file\n",
    "\n",
    "The memes are organized like so;\n",
    "/memes/Topic 1\n",
    "/memes/Topic 2\n",
    "\n",
    "Memes can be images or videos. Assume all the common file extensions will be present. For each meme, a number of metadata files may be present. These should be included if present.\n",
    "\n",
    "For example;\n",
    "memefilename.jpg\n",
    "memefilename.jpg.txt <- Canonical tesseract-OCR of the meme. Might be nonsense. Probably we won't need this but it's there, so lets include it in the json file.\n",
    "memefilename.jpg.llama-3.2-vision.txt <- High quality transformer analysis of the image, containing detailed explanation of the visual elements of the image, including any text, but probably lacking an awareness of any social context or any relationship to current events.\n",
    "\n",
    "Example output:\n",
    "\n",
    "'Topic 1' => {\n",
    "    1 => {\n",
    "        'file' => 'memes/topic/filename.jpg',\n",
    "        'filemtime' => 'date the file was last modified',\n",
    "        'metadata' => {\n",
    "            'tesseract-ocr' => 'memes/topic/filename.jpg.txt',\n",
    "            'llama-3.2-vision' => 'memes/topic/filename.jpg.llama-3.2-vision.txt'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "The list of memes in each topic must be ordered by filemtime descending, such that the most recently added item is number 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def get_file_timestamp(file: Path) -> datetime:\n",
    "    \n",
    "    file = Path(file)\n",
    "    \n",
    "    meta_path = file.with_name(file.name + \".first-seen.txt\")\n",
    "\n",
    "    if meta_path.exists():\n",
    "        # Read the timestamp from first-seen.txt\n",
    "        mod_time_str = meta_path.read_text().strip()\n",
    "        return mod_time_str\n",
    "    else:\n",
    "        # Fallback to current modification time\n",
    "        return datetime.fromtimestamp(file.stat().st_mtime, tz=timezone.utc).isoformat()\n",
    "    \n",
    "def get_topics():\n",
    "    \"\"\"Return list of topic folders in the memes directory\"\"\"\n",
    "    return [p.name for p in MEMES_ROOT.iterdir() if p.is_dir()]\n",
    "\n",
    "def process_topic(topic: str) -> dict[int, dict]:\n",
    "    topic_path = Path(MEMES_ROOT) / topic\n",
    "    memes: list[dict] = []\n",
    "\n",
    "    for meme_file in topic_path.iterdir():\n",
    "        if meme_file.suffix.lower() not in TRACKED_EXTS or not meme_file.is_file():\n",
    "            continue\n",
    "\n",
    "        memes.append({\n",
    "            \"file\": str(meme_file),\n",
    "            \"filemtime\": get_file_timestamp(meme_file),   # dt obj\n",
    "            \"metadata\": {\n",
    "                k: str(meme_file.with_name(meme_file.name + suffix))\n",
    "                for k, suffix in {\n",
    "                    \"tesseract-ocr\": \".txt\",\n",
    "                    \"llama-3.2-vision\": \".llama-3.2-vision.txt\"\n",
    "                }.items()\n",
    "                if meme_file.with_name(meme_file.name + suffix).exists()\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # newest first\n",
    "    memes.sort(key=lambda m: m[\"filemtime\"], reverse=True)\n",
    "\n",
    "    # re-index so 1 == newest\n",
    "    return {i: _serialise(meme) for i, meme in enumerate(memes, 1)}\n",
    "\n",
    "def _serialise(meme: dict) -> dict:\n",
    "    \"\"\"Convert dt → iso-string without microseconds so JSON dump works.\"\"\"\n",
    "    meme = meme.copy()\n",
    "    meme[\"filemtime\"] = meme[\"filemtime\"]\n",
    "    return meme\n",
    "\n",
    "def build_master_json():\n",
    "    \"\"\"Build the master JSON file with all topics and all memes\"\"\"\n",
    "    master_dict = {}\n",
    "\n",
    "    for topic in get_topics():\n",
    "        master_dict[topic] = process_topic(topic)\n",
    "\n",
    "    # Sort each topic's memes by filemtime descending\n",
    "    for topic, memes in master_dict.items():\n",
    "        sorted_memes = dict(sorted(memes.items(), key=lambda item: item[1]['filemtime'], reverse=True))\n",
    "        master_dict[topic] = sorted_memes\n",
    "\n",
    "    return master_dict\n",
    "\n",
    "master_json_data = build_master_json()\n",
    "\n",
    "\n",
    "## Save JSON File\n",
    "\n",
    "with open('memes.json', 'w') as json_file:\n",
    "    json.dump(master_json_data, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate missing llama-3.2-vision.txt files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64, requests, textwrap, time\n",
    "from pathlib import Path\n",
    "from requests.exceptions import RequestException\n",
    "\n",
    "MODEL_NAME   = \"llama3.2-vision:11b\"\n",
    "OLLAMA_URL   = \"http://docker-ai:11434/api/generate\"\n",
    "PROMPT       = (\n",
    "    \"In 2-3 sentences, describe this meme for someone who cannot see it. \"\n",
    "    \"Include any text that appears in the image.\"\n",
    ")\n",
    "IMAGE_EXTS   = {\".gif\", \".jfif\", \".jpeg\", \".jpg\", \".png\", \".svg\", \".webp\"}\n",
    "\n",
    "MAX_RETRIES  = 3        # total attempts per image\n",
    "INITIAL_WAIT = 5        # seconds before first retry (doubles each time)\n",
    "\n",
    "def _meta_path(img: Path) -> Path:\n",
    "    return img.with_name(f\"{img.name}.llama3.2-vision.txt\")\n",
    "\n",
    "def _summarise_image(img: Path) -> str:\n",
    "    \"\"\"Call Ollama with retries; raise after MAX_RETRIES failures.\"\"\"\n",
    "    img_b64  = base64.b64encode(img.read_bytes()).decode()\n",
    "    payload  = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"prompt\": PROMPT,\n",
    "        \"stream\": False,\n",
    "        \"images\": [img_b64],\n",
    "    }\n",
    "\n",
    "    for attempt in range(1, MAX_RETRIES + 1):\n",
    "        try:\n",
    "            r = requests.post(OLLAMA_URL, json=payload, timeout=300)\n",
    "            r.raise_for_status()\n",
    "            summary = r.json().get(\"response\", \"\").strip()\n",
    "            if not summary:\n",
    "                raise ValueError(\"API returned empty 'response'\")\n",
    "            return summary\n",
    "\n",
    "        except (RequestException, ValueError) as err:\n",
    "            wait = INITIAL_WAIT * 2 ** (attempt - 1)\n",
    "            print(f\"[{img.name}] attempt {attempt}/{MAX_RETRIES} failed: {err}\")\n",
    "            if attempt < MAX_RETRIES:\n",
    "                print(f\"   → retrying in {wait}s …\")\n",
    "                time.sleep(wait)\n",
    "            else:\n",
    "                raise  # bubbled up to main loop\n",
    "\n",
    "def create_all_summaries(root=MEMES_ROOT):\n",
    "    skipped, made = 0, 0\n",
    "    for img in Path(root).rglob(\"*\"):\n",
    "        if img.suffix.lower() not in IMAGE_EXTS or _meta_path(img).exists():\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            summary = _summarise_image(img)\n",
    "            meta    = _meta_path(img)\n",
    "            meta.write_text(summary + \"\\n\", encoding=\"utf-8\")\n",
    "            made += 1\n",
    "\n",
    "            print(f\"\\n⟹  {img.relative_to(root)}\")\n",
    "            print(textwrap.fill(summary, width=88))\n",
    "            print(f\"— saved to {meta.name} —\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            skipped += 1\n",
    "            print(f\"[skip] {img.relative_to(root)} → {e}\")\n",
    "\n",
    "    print(f\"\\n✓ Done. {made} files written, {skipped} skipped after retries.\")\n",
    "\n",
    "# create_all_summaries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a markdown file for each meme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x9d in position 111: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     34\u001b[39m                 lines.append(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m<p>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontent\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m</p>\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     36\u001b[39m         md_file.write_text(\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m.join(lines), encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[43mcreate_markdown_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mcreate_markdown_files\u001b[39m\u001b[34m(root)\u001b[39m\n\u001b[32m     30\u001b[39m meta_path = meme.with_name(meme.name + META_SUFFIXES[meta])\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m meta_path.exists():\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     content = \u001b[43mmeta_path\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.strip()\n\u001b[32m     33\u001b[39m     lines.append(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m<h2>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmeta\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m</h2>\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     34\u001b[39m     lines.append(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m<p>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontent\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m</p>\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CJ\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\pathlib.py:1029\u001b[39m, in \u001b[36mPath.read_text\u001b[39m\u001b[34m(self, encoding, errors)\u001b[39m\n\u001b[32m   1027\u001b[39m encoding = io.text_encoding(encoding)\n\u001b[32m   1028\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.open(mode=\u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m, encoding=encoding, errors=errors) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m-> \u001b[39m\u001b[32m1029\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CJ\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\encodings\\cp1252.py:23\u001b[39m, in \u001b[36mIncrementalDecoder.decode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcodecs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcharmap_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdecoding_table\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mUnicodeDecodeError\u001b[39m: 'charmap' codec can't decode byte 0x9d in position 111: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "META_ORDER = [\"llama-3.2-vision\", \"tesseract\", \"first-seen\"]\n",
    "META_SUFFIXES = {\n",
    "    \"llama-3.2-vision\": \".llama-3.2-vision.txt\",\n",
    "    \"tesseract\": \".txt\",\n",
    "    \"first-seen\": \".first-seen.txt\",\n",
    "}\n",
    "\n",
    "def create_markdown_files(root=MEMES_ROOT):\n",
    "    root = Path(root)\n",
    "    for meme in root.rglob('*'):\n",
    "        if meme.suffix.lower() not in TRACKED_EXTS or not meme.is_file():\n",
    "            continue\n",
    "\n",
    "        md_file = meme.with_name(meme.name + '.md')\n",
    "        lines = [\n",
    "            '---',\n",
    "            'layout: default',\n",
    "            f'title: {meme.name}',\n",
    "            '---',\n",
    "        ]\n",
    "\n",
    "        if meme.suffix.lower() in IMAGE_EXTS:\n",
    "            lines.append(f'<a href=\"{meme.name}\"><img class=\"photo\" src=\"{meme.name}\" /></a>')\n",
    "        else:\n",
    "            lines.append(f'[Download {meme.name}]({meme.name})')\n",
    "\n",
    "        for meta in META_ORDER:\n",
    "            meta_path = meme.with_name(meme.name + META_SUFFIXES[meta])\n",
    "            if meta_path.exists():\n",
    "                content = meta_path.read_text().strip()\n",
    "                lines.append(f'<h2>{meta}</h2>')\n",
    "                lines.append(f'<p>{content}</p>')\n",
    "\n",
    "        md_file.write_text(''.join(lines), encoding='utf-8')\n",
    "\n",
    "create_markdown_files()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate new markdown files for each category directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
